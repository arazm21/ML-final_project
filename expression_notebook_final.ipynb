{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "view-in-github",
    "colab_type": "text"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/arazm21/ML-homework_4/blob/main/expression_notebook_final.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ],
   "id": "ecb861fb16ad7fed"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# loading the data and organising it"
   ],
   "metadata": {
    "id": "ShlkPaeoBQ3k"
   },
   "id": "ShlkPaeoBQ3k"
  },
  {
   "cell_type": "code",
   "source": [
    "! pip install kaggle\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "! mkdir ~/.kaggle\n",
    "!cp /content/drive/MyDrive/ColabNotebooks/kaggle_API_credentials/kaggle.json ~/.kaggle/kaggle.json\n",
    "! chmod 600 ~/.kaggle/kaggle.json\n",
    "! kaggle competitions download -c challenges-in-representation-learning-facial-expression-recognition-challenge\n",
    "! unzip challenges-in-representation-learning-facial-expression-recognition-challenge"
   ],
   "metadata": {
    "collapsed": true,
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dNNvBwljBQFE",
    "outputId": "e78fee55-f892-4a63-f710-3f5bce74527f"
   },
   "id": "dNNvBwljBQFE",
   "execution_count": 1,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Requirement already satisfied: kaggle in /usr/local/lib/python3.11/dist-packages (1.7.4.5)\n",
      "Requirement already satisfied: bleach in /usr/local/lib/python3.11/dist-packages (from kaggle) (6.2.0)\n",
      "Requirement already satisfied: certifi>=14.05.14 in /usr/local/lib/python3.11/dist-packages (from kaggle) (2025.4.26)\n",
      "Requirement already satisfied: charset-normalizer in /usr/local/lib/python3.11/dist-packages (from kaggle) (3.4.2)\n",
      "Requirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from kaggle) (3.10)\n",
      "Requirement already satisfied: protobuf in /usr/local/lib/python3.11/dist-packages (from kaggle) (5.29.5)\n",
      "Requirement already satisfied: python-dateutil>=2.5.3 in /usr/local/lib/python3.11/dist-packages (from kaggle) (2.9.0.post0)\n",
      "Requirement already satisfied: python-slugify in /usr/local/lib/python3.11/dist-packages (from kaggle) (8.0.4)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from kaggle) (2.32.3)\n",
      "Requirement already satisfied: setuptools>=21.0.0 in /usr/local/lib/python3.11/dist-packages (from kaggle) (75.2.0)\n",
      "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.11/dist-packages (from kaggle) (1.17.0)\n",
      "Requirement already satisfied: text-unidecode in /usr/local/lib/python3.11/dist-packages (from kaggle) (1.3)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from kaggle) (4.67.1)\n",
      "Requirement already satisfied: urllib3>=1.15.1 in /usr/local/lib/python3.11/dist-packages (from kaggle) (2.4.0)\n",
      "Requirement already satisfied: webencodings in /usr/local/lib/python3.11/dist-packages (from kaggle) (0.5.1)\n",
      "Mounted at /content/drive\n",
      "Downloading challenges-in-representation-learning-facial-expression-recognition-challenge.zip to /content\n",
      " 83% 236M/285M [00:00<00:00, 802MB/s] \n",
      "100% 285M/285M [00:00<00:00, 827MB/s]\n",
      "Archive:  challenges-in-representation-learning-facial-expression-recognition-challenge.zip\n",
      "  inflating: example_submission.csv  \n",
      "  inflating: fer2013.tar.gz          \n",
      "  inflating: icml_face_data.csv      \n",
      "  inflating: test.csv                \n",
      "  inflating: train.csv               \n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "!pip install onnx"
   ],
   "metadata": {
    "id": "9fXPkihKllSZ",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "1b5c36af-f6f4-4491-ec12-32d60dc2987e"
   },
   "id": "9fXPkihKllSZ",
   "execution_count": 2,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Collecting onnx\n",
      "  Downloading onnx-1.18.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.9 kB)\n",
      "Requirement already satisfied: numpy>=1.22 in /usr/local/lib/python3.11/dist-packages (from onnx) (2.0.2)\n",
      "Requirement already satisfied: protobuf>=4.25.1 in /usr/local/lib/python3.11/dist-packages (from onnx) (5.29.5)\n",
      "Requirement already satisfied: typing_extensions>=4.7.1 in /usr/local/lib/python3.11/dist-packages (from onnx) (4.13.2)\n",
      "Downloading onnx-1.18.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.6 MB)\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m17.6/17.6 MB\u001B[0m \u001B[31m50.1 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hInstalling collected packages: onnx\n",
      "Successfully installed onnx-1.18.0\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "import torch # Main PyTorch Library\n",
    "from torch import nn # Used for creating the layers and loss function\n",
    "from torch.optim import Adam # Adam Optimizer\n",
    "import torchvision.transforms as transforms # Transform function used to modify and preprocess all the images\n",
    "from torch.utils.data import Dataset, DataLoader # Dataset class and DataLoader for creating the objects\n",
    "from sklearn.preprocessing import LabelEncoder # Label Encoder to encode the classes from strings to numbers\n",
    "import matplotlib.pyplot as plt # Used for visualizing the images and plotting the training progress\n",
    "from PIL import Image # Used to read the images from the directory\n",
    "import pandas as pd # Used to read/create dataframes (csv) and process tabular data\n",
    "import numpy as np # preprocessing and numerical/mathematical operations\n",
    "import os # Used to read the images path from the directory\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\" # detect the GPU if any, if not use CPU, change cuda to mps if you have a mac\n",
    "print(\"Device available: \", device)"
   ],
   "metadata": {
    "id": "xib5nVmSLH0o",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "98b1a2e2-5a66-4aa6-8cbe-642a0a2cf3c9"
   },
   "id": "xib5nVmSLH0o",
   "execution_count": 3,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Device available:  cuda\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from collections import Counter\n",
    "import random\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "\n",
    "# ─── 1) Augmentations for minority classes ────────────────────────────────────\n",
    "\n",
    "aug_transform = transforms.Compose([\n",
    "    transforms.RandomRotation(10),\n",
    "    transforms.ColorJitter(brightness=0.3, contrast=0.3),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    # transforms.RandomAffine(degrees=0, translate=(0.1, 0.1)),\n",
    "    transforms.ToTensor(),  # finally convert to tensor in [0,1]\n",
    "])\n",
    "\n",
    "# ─── 2) Base “no‐transform” behavior ─────────────────────────────────────────\n",
    "\n",
    "class ExpressionDatasetFromDF(Dataset):\n",
    "    def __init__(self, dataframe):\n",
    "        # Expect columns exactly [\"emotion\", \"pixels\", \"Usage\"]\n",
    "        # Each “pixels” entry is a string of “230  19  …”\n",
    "        self.images = dataframe[\" pixels\"].apply(\n",
    "            lambda x: np.fromstring(x, sep=\" \", dtype=np.uint8).reshape(48, 48)\n",
    "        )\n",
    "        # Stack into a (N, 1, 48, 48) float32 tensor in [0,1]\n",
    "        self.images = torch.tensor(\n",
    "            np.stack(self.images.values), dtype=torch.float32\n",
    "        ).unsqueeze(1) / 255.0\n",
    "        self.labels = torch.tensor(dataframe[\"emotion\"].values, dtype=torch.long)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.images[idx], self.labels[idx]\n",
    "\n",
    "\n",
    "# ─── 3) Oversampling / augmentation wrapper ──────────────────────────────────\n",
    "\n",
    "class AugmentedExpressionDataset(Dataset):\n",
    "    def __init__(self, base_dataset, targets, num_aug_per_sample=1):\n",
    "        \"\"\"\n",
    "        base_dataset: an ExpressionDatasetFromDF (no transforms applied)\n",
    "        targets: list of ints (same length as base_dataset)\n",
    "        \"\"\"\n",
    "        self.base_dataset = base_dataset\n",
    "        self.targets = targets\n",
    "        self.class_counts = Counter(targets)\n",
    "        self.max_count = max(self.class_counts.values())\n",
    "\n",
    "        # Build a list of “base indices” to duplicate + augment\n",
    "        self.augmented_indices = []\n",
    "        for cls_label, count in self.class_counts.items():\n",
    "            n_to_add = self.max_count - count\n",
    "            if n_to_add <= 0:\n",
    "                continue\n",
    "            # pick with replacement from all indices whose target == cls_label\n",
    "            indices_of_cls = [\n",
    "                i for i, t in enumerate(targets) if t == cls_label\n",
    "            ]\n",
    "            sampled = random.choices(indices_of_cls, k=n_to_add * num_aug_per_sample)\n",
    "            self.augmented_indices.extend(sampled)\n",
    "\n",
    "        print(f\"‣ Base dataset size: {len(self.base_dataset)}\")\n",
    "        print(f\"‣ Augmenting {len(self.augmented_indices)} extra samples to balance classes.\")\n",
    "        print(f\"‣ Resulting dataset size: {len(self.base_dataset) + len(self.augmented_indices)}\")\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.base_dataset) + len(self.augmented_indices)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if idx < len(self.base_dataset):\n",
    "            # no augmentation for the “original” sample\n",
    "            img_tensor, label = self.base_dataset[idx]\n",
    "            return img_tensor, label\n",
    "        else:\n",
    "            # for augmented ones: take the base index, convert back to PIL, augment, then ToTensor\n",
    "            base_idx = self.augmented_indices[idx - len(self.base_dataset)]\n",
    "            img_tensor, label = self.base_dataset[base_idx]\n",
    "            # img_tensor is (1,48,48) float in [0,1]. Convert back to uint8 PIL:\n",
    "            arr_uint8 = (img_tensor.squeeze().numpy() * 255).astype(np.uint8)\n",
    "            pil_img = Image.fromarray(arr_uint8, mode=\"L\")\n",
    "            img_aug = aug_transform(pil_img)  # now a (1,48,48) FloatTensor in [0,1]\n",
    "            return img_aug, label\n",
    "\n",
    "\n",
    "# ─── 4) Revised get_data (no more “slice”) ───────────────────────────────────\n",
    "\n",
    "def get_data(csv_file=\"icml_face_data.csv\", train=True):\n",
    "    \"\"\"\n",
    "    - Reads icml_face_data.csv (which has exactly [\"emotion\",\"pixels\",\"Usage\"]).\n",
    "    - Splits by Usage == \"Training\" vs. \"PublicTest\".\n",
    "    - For train: wraps in AugmentedExpressionDataset. For test/val: returns raw dataset.\n",
    "    \"\"\"\n",
    "    full_df = pd.read_csv(csv_file)\n",
    "\n",
    "    if train:\n",
    "        df_part = full_df[full_df[\" Usage\"] == \"Training\"].reset_index(drop=True)\n",
    "    else:\n",
    "        df_part = full_df[full_df[\" Usage\"] == \"PublicTest\"].reset_index(drop=True)\n",
    "\n",
    "    print(f\"‣ Loaded '{'Training' if train else 'PublicTest'}' => {len(df_part)} samples before augmentation/slicing.\")\n",
    "\n",
    "    base_ds = ExpressionDatasetFromDF(df_part)\n",
    "\n",
    "    if train:\n",
    "        targets = df_part[\"emotion\"].tolist()\n",
    "        balanced_ds = AugmentedExpressionDataset(base_ds, targets)\n",
    "        return balanced_ds\n",
    "    else:\n",
    "        return base_ds\n",
    "\n",
    "\n",
    "def make_loader(dataset, batch_size):\n",
    "    return DataLoader(\n",
    "        dataset=dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=True,\n",
    "        pin_memory=True,\n",
    "        num_workers=1,\n",
    "    )\n"
   ],
   "metadata": {
    "id": "b5Ptu8H4Lzx6"
   },
   "id": "b5Ptu8H4Lzx6",
   "execution_count": 4,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from collections import Counter\n",
    "import random\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "\n",
    "# ─── 1) Augmentations for minority classes ────────────────────────────────────\n",
    "\n",
    "aug_transform = transforms.Compose([\n",
    "    transforms.RandomRotation(20),\n",
    "    transforms.ColorJitter(brightness=0.3, contrast=0.3),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomAffine(degrees=0, translate=(0.1, 0.1)),\n",
    "    transforms.ToTensor(),  # finally convert to tensor in [0,1]\n",
    "])\n",
    "\n",
    "# ─── 2) Base “no‐transform” behavior ─────────────────────────────────────────\n",
    "\n",
    "class ExpressionDatasetFromDF(Dataset):\n",
    "    def __init__(self, dataframe):\n",
    "        # Expect columns exactly [\"emotion\", \"pixels\", \"Usage\"]\n",
    "        # Each “pixels” entry is a string of “230  19  …”\n",
    "        self.images = dataframe[\" pixels\"].apply(\n",
    "            lambda x: np.fromstring(x, sep=\" \", dtype=np.uint8).reshape(48, 48)\n",
    "        )\n",
    "        # Stack into a (N, 1, 48, 48) float32 tensor in [0,1]\n",
    "        self.images = torch.tensor(\n",
    "            np.stack(self.images.values), dtype=torch.float32\n",
    "        ).unsqueeze(1) / 255.0\n",
    "        self.labels = torch.tensor(dataframe[\"emotion\"].values, dtype=torch.long)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.images[idx], self.labels[idx]\n",
    "\n",
    "\n",
    "# ─── 3) Oversampling / augmentation wrapper ──────────────────────────────────\n",
    "\n",
    "class AugmentedExpressionDataset(Dataset):\n",
    "    def __init__(self, base_dataset, targets, num_aug_per_sample=1):\n",
    "        \"\"\"\n",
    "        base_dataset: an ExpressionDatasetFromDF (no transforms applied)\n",
    "        targets: list of ints (same length as base_dataset)\n",
    "        \"\"\"\n",
    "        self.base_dataset = base_dataset\n",
    "        self.targets = targets\n",
    "        self.class_counts = Counter(targets)\n",
    "        self.max_count = max(self.class_counts.values())\n",
    "\n",
    "        # Build a list of “base indices” to duplicate + augment\n",
    "        self.augmented_indices = []\n",
    "        for cls_label, count in self.class_counts.items():\n",
    "            n_to_add = self.max_count - count\n",
    "            if n_to_add <= 0:\n",
    "                continue\n",
    "            # pick with replacement from all indices whose target == cls_label\n",
    "            indices_of_cls = [\n",
    "                i for i, t in enumerate(targets) if t == cls_label\n",
    "            ]\n",
    "            sampled = random.choices(indices_of_cls, k=n_to_add * num_aug_per_sample)\n",
    "            self.augmented_indices.extend(sampled)\n",
    "\n",
    "        print(f\"‣ Base dataset size: {len(self.base_dataset)}\")\n",
    "        print(f\"‣ Augmenting {len(self.augmented_indices)} extra samples to balance classes.\")\n",
    "        print(f\"‣ Resulting dataset size: {len(self.base_dataset) + len(self.augmented_indices)}\")\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.base_dataset) + len(self.augmented_indices)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if idx < len(self.base_dataset):\n",
    "            # no augmentation for the “original” sample\n",
    "            img_tensor, label = self.base_dataset[idx]\n",
    "            return img_tensor, label\n",
    "        else:\n",
    "            # for augmented ones: take the base index, convert back to PIL, augment, then ToTensor\n",
    "            base_idx = self.augmented_indices[idx - len(self.base_dataset)]\n",
    "            img_tensor, label = self.base_dataset[base_idx]\n",
    "            # img_tensor is (1,48,48) float in [0,1]. Convert back to uint8 PIL:\n",
    "            arr_uint8 = (img_tensor.squeeze().numpy() * 255).astype(np.uint8)\n",
    "            pil_img = Image.fromarray(arr_uint8, mode=\"L\")\n",
    "            img_aug = aug_transform(pil_img)  # now a (1,48,48) FloatTensor in [0,1]\n",
    "            return img_aug, label\n",
    "\n",
    "\n",
    "# ─── 4) Revised get_data (no more “slice”) ───────────────────────────────────\n",
    "\n",
    "def get_data(csv_file=\"icml_face_data.csv\", train=True, test=False):\n",
    "    \"\"\"\n",
    "    - Reads icml_face_data.csv (which has exactly [\"emotion\",\"pixels\",\"Usage\"]).\n",
    "    - Splits by Usage == \"Training\" vs. \"PublicTest\".\n",
    "    - For train: wraps in AugmentedExpressionDataset. For test/val: returns raw dataset.\n",
    "    \"\"\"\n",
    "    full_df = pd.read_csv(csv_file)\n",
    "\n",
    "    if train:\n",
    "        df_part = full_df[full_df[\" Usage\"] == \"Training\"].reset_index(drop=True)\n",
    "    elif test==False:\n",
    "        df_part = full_df[full_df[\" Usage\"] == \"PublicTest\"].reset_index(drop=True)\n",
    "    else:\n",
    "        df_part = full_df[full_df[\" Usage\"] == \"PrivateTest\"].reset_index(drop=True)\n",
    "    print(f\"‣ Loaded '{'Training' if train else 'PublicTest'}' => {len(df_part)} samples before augmentation/slicing.\")\n",
    "\n",
    "    base_ds = ExpressionDatasetFromDF(df_part)\n",
    "\n",
    "    if train:\n",
    "        targets = df_part[\"emotion\"].tolist()\n",
    "        balanced_ds = AugmentedExpressionDataset(base_ds, targets)\n",
    "        return balanced_ds\n",
    "    else:\n",
    "        return base_ds\n",
    "\n",
    "\n",
    "def make_loader(dataset, batch_size):\n",
    "    return DataLoader(\n",
    "        dataset=dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=True,\n",
    "        pin_memory=True,\n",
    "        num_workers=2,\n",
    "    )\n",
    "\n",
    "\n",
    "# ─── 5) Quick sanity check ───────────────────────────────────────────────────\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # 1) Inspect base “Training” size (should be ~28,709 for FER2013).\n",
    "    train_ds = get_data(csv_file=\"icml_face_data.csv\", train=True)\n",
    "    print(f\"Len of train_ds (after augmentation): {len(train_ds)}\\n\")\n",
    "\n",
    "    # 2) Inspect base “PublicTest” size (should be ~3,589).\n",
    "    val_ds = get_data(csv_file=\"icml_face_data.csv\", train=False)\n",
    "    print(f\"Len of val_ds (no augmentation): {len(val_ds)}\\n\")\n",
    "\n",
    "    # 3) Create DataLoader and confirm iteration count\n",
    "    train_loader = make_loader(train_ds, batch_size=64)\n",
    "    total_seen = sum(len(batch[0]) for batch in train_loader)\n",
    "    print(f\"Total images seen via train_loader: {total_seen}\")\n"
   ],
   "metadata": {
    "id": "D1ye0F1iHqSC",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "872887e5-226c-498d-eec5-b5ae5b2d1a12"
   },
   "id": "D1ye0F1iHqSC",
   "execution_count": 16,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "‣ Loaded 'Training' => 28709 samples before augmentation/slicing.\n",
      "‣ Base dataset size: 28709\n",
      "‣ Augmenting 21796 extra samples to balance classes.\n",
      "‣ Resulting dataset size: 50505\n",
      "Len of train_ds (after augmentation): 50505\n",
      "\n",
      "‣ Loaded 'PublicTest' => 3589 samples before augmentation/slicing.\n",
      "Len of val_ds (no augmentation): 3589\n",
      "\n",
      "Total images seen via train_loader: 50505\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## test that loading was ok"
   ],
   "metadata": {
    "id": "RsFhOzV_PHxI"
   },
   "id": "RsFhOzV_PHxI"
  },
  {
   "cell_type": "code",
   "source": [
    "# Load and create loader\n",
    "dataset = get_data(train=False)\n",
    "loader = make_loader(dataset, batch_size=3)\n",
    "\n",
    "# Get a batch\n",
    "images, labels = next(iter(loader))\n",
    "\n",
    "# Class names from FER2013\n",
    "emotion_names = [\n",
    "    \"Angry\", \"Disgust\", \"Fear\", \"Happy\", \"Sad\", \"Surprise\", \"Neutral\"\n",
    "]\n",
    "\n",
    "# Plot the first 3 images\n",
    "plt.figure(figsize=(10, 4))\n",
    "for i in range(3):\n",
    "    plt.subplot(1, 3, i + 1)\n",
    "    plt.imshow(images[i][0], cmap='gray')\n",
    "    plt.title(f\"Label: {emotion_names[labels[i].item()]}\")\n",
    "    plt.axis('off')\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ],
   "metadata": {
    "id": "NvgplaWYHJX6",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 389
    },
    "outputId": "77ad8bbf-4258-4402-8e3a-4ccdb7ec986f"
   },
   "id": "NvgplaWYHJX6",
   "execution_count": 6,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "‣ Loaded 'PublicTest' => 3589 samples before augmentation/slicing.\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "<Figure size 1000x400 with 3 Axes>"
      ],
      "image/png": "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\n"
     },
     "metadata": {}
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# connecting WANDB"
   ],
   "metadata": {
    "id": "XhwXYgieSf7u"
   },
   "id": "XhwXYgieSf7u"
  },
  {
   "cell_type": "code",
   "source": [
    "import os\n",
    "import random\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "# Ensure deterministic behavior\n",
    "torch.backends.cudnn.deterministic = True\n",
    "random.seed(hash(\"setting random seeds\") % 2**32 - 1)\n",
    "np.random.seed(hash(\"improves reproducibility\") % 2**32 - 1)\n",
    "torch.manual_seed(hash(\"by removing stochasticity\") % 2**32 - 1)\n",
    "torch.cuda.manual_seed_all(hash(\"so runs are repeatable\") % 2**32 - 1)\n",
    "\n",
    "# Device configuration\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n"
   ],
   "metadata": {
    "id": "zt2tymF2Se4p"
   },
   "id": "zt2tymF2Se4p",
   "execution_count": 7,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "import wandb\n",
    "wandb.login()"
   ],
   "metadata": {
    "id": "l2Op72b3SsY1",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 191
    },
    "outputId": "324856e6-c74c-4701-9bc9-8adcaea1993d"
   },
   "id": "l2Op72b3SsY1",
   "execution_count": 8,
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ],
      "application/javascript": [
       "\n",
       "        window._wandbApiKey = new Promise((resolve, reject) => {\n",
       "            function loadScript(url) {\n",
       "            return new Promise(function(resolve, reject) {\n",
       "                let newScript = document.createElement(\"script\");\n",
       "                newScript.onerror = reject;\n",
       "                newScript.onload = resolve;\n",
       "                document.body.appendChild(newScript);\n",
       "                newScript.src = url;\n",
       "            });\n",
       "            }\n",
       "            loadScript(\"https://cdn.jsdelivr.net/npm/postmate/build/postmate.min.js\").then(() => {\n",
       "            const iframe = document.createElement('iframe')\n",
       "            iframe.style.cssText = \"width:0;height:0;border:none\"\n",
       "            document.body.appendChild(iframe)\n",
       "            const handshake = new Postmate({\n",
       "                container: iframe,\n",
       "                url: 'https://wandb.ai/authorize'\n",
       "            });\n",
       "            const timeout = setTimeout(() => reject(\"Couldn't auto authenticate\"), 5000)\n",
       "            handshake.then(function(child) {\n",
       "                child.on('authorize', data => {\n",
       "                    clearTimeout(timeout)\n",
       "                    resolve(data)\n",
       "                });\n",
       "            });\n",
       "            })\n",
       "        });\n",
       "    "
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\u001B[34m\u001B[1mwandb\u001B[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n",
      "wandb: Paste an API key from your profile and hit enter:"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ··········\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\u001B[34m\u001B[1mwandb\u001B[0m: \u001B[33mWARNING\u001B[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: \u001B[33mWARNING\u001B[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: No netrc file found, creating one.\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: Currently logged in as: \u001B[33marazm21\u001B[0m (\u001B[33marazm21-free-university-of-tbilisi-\u001B[0m) to \u001B[32mhttps://api.wandb.ai\u001B[0m. Use \u001B[1m`wandb login --relogin`\u001B[0m to force relogin\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "metadata": {},
     "execution_count": 8
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# different attempted architectures"
   ],
   "metadata": {
    "id": "FjvVv9RPXFbN"
   },
   "id": "FjvVv9RPXFbN"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# geting everything ready"
   ],
   "metadata": {
    "id": "zaVbntQmXODJ"
   },
   "id": "zaVbntQmXODJ"
  },
  {
   "cell_type": "code",
   "source": [
    "def make(config):\n",
    "    # Make the data\n",
    "    train_dataset = get_data(train=True)\n",
    "    test_dataset = get_data(train=False)\n",
    "    final_test_dataset = get_data(train=False, test=True)\n",
    "    train_loader = make_loader(train_dataset, batch_size=config.batch_size)\n",
    "    test_loader = make_loader(test_dataset, batch_size=config.batch_size)\n",
    "    final_test_loader = make_loader(final_test_dataset, batch_size=config.batch_size)\n",
    "    # Make the model\n",
    "    model = k(block, [2, 2, 2,2], 1, 7).to(device)\n",
    "    # model = timm.create_model('convit_tiny', pretrained=True, num_classes=7).to(device)\n",
    "    # model = ViT(\n",
    "    #     image_size=48,\n",
    "    #     patch_size=6,\n",
    "    #     num_classes=7,\n",
    "    #     dim=128,          # embedding dimension\n",
    "    #     depth=6,          # number of transformer layers\n",
    "    #     heads=4,          # number of self-attention heads\n",
    "    #     mlp_dim=256,      # hidden dim in the feedforward\n",
    "    #     pool='cls',       # use cls token pooling\n",
    "    #     channels=1,       # grayscale input\n",
    "    #     dim_head=32,      # dimension per attention head\n",
    "    #     dropout=0.1,      # transformer dropout\n",
    "    #     emb_dropout=0.1   # dropout after patch+pos embedding\n",
    "    # ).to(device)\n",
    "    # model = ViT(\n",
    "    #     image_size=48,\n",
    "    #     patch_size=6,\n",
    "    #     num_classes=7,\n",
    "    #     dim=256,          # embedding dim\n",
    "    #     depth=12,          # transformer depth (layers)\n",
    "    #     heads=6,          # number of attention heads\n",
    "    #     mlp_dim=512,      # feedforward hidden layer size\n",
    "    #     pool='cls',       # cls token pooling\n",
    "    #     channels=1,       # grayscale image\n",
    "    #     dim_head=64,      # per-head dimension\n",
    "    #     dropout=0.2,      # transformer dropout\n",
    "    #     emb_dropout=0.1,  # embedding dropout\n",
    "    #     patch_dropout=0.1 # optional patch dropout\n",
    "    # ).to(device)\n",
    "    # model = SimpleViT(\n",
    "    #     num_classes = 7,\n",
    "    #     image_size = 256,\n",
    "    #     patch_size = 8,\n",
    "    #     dim = 1024,\n",
    "    #     depth = 12,\n",
    "    #     heads = 8,\n",
    "    #     mlp_dim = 2048,\n",
    "    #     num_residual_streams = 8\n",
    "    # ).to(device)\n",
    "\n",
    "    # Make the loss and optimizer\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=config.learning_rate, weight_decay=config.weight_decay)\n",
    "\n",
    "    return model, train_loader, test_loader, criterion, optimizer, final_test_loader"
   ],
   "metadata": {
    "id": "4GOnNEKyT1v2"
   },
   "id": "4GOnNEKyT1v2",
   "execution_count": 82,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "def train_log(loss, example_ct, epoch):\n",
    "    # Where the magic happens\n",
    "    wandb.log({\"epoch\": epoch, \"loss\": loss}, step=example_ct)\n",
    "    print(f\"Loss after {str(example_ct).zfill(5)} examples: {loss:.3f}\")"
   ],
   "metadata": {
    "id": "Jwbd9gvXUp4R"
   },
   "id": "Jwbd9gvXUp4R",
   "execution_count": 69,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## early stop training"
   ],
   "metadata": {
    "id": "6Vih9mc96ns6"
   },
   "id": "6Vih9mc96ns6"
  },
  {
   "cell_type": "code",
   "source": [
    "class EarlyStopping:\n",
    "    def __init__(self, patience=5, min_delta=0.0):\n",
    "        self.patience = patience\n",
    "        self.min_delta = min_delta\n",
    "        self.best_loss = float('inf')\n",
    "        self.counter = 0\n",
    "        self.early_stop = False\n",
    "\n",
    "    def __call__(self, val_loss):\n",
    "        if val_loss < self.best_loss - self.min_delta:\n",
    "            self.best_loss = val_loss\n",
    "            self.counter = 0\n",
    "        else:\n",
    "            self.counter += 1\n",
    "            if self.counter >= self.patience:\n",
    "                self.early_stop = True\n",
    "\n",
    "def validate(model, val_loader, criterion):\n",
    "    model.eval()\n",
    "    total = 0\n",
    "    correct = 0\n",
    "    val_loss = 0.0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in val_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            val_loss += loss.item() * images.size(0)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    val_loss /= total\n",
    "    val_acc = correct / total\n",
    "    return val_loss, val_acc\n",
    "\n",
    "def train(model, train_loader, val_loader, criterion, optimizer, config):\n",
    "    wandb.watch(model, criterion, log=\"all\", log_freq=10)\n",
    "\n",
    "    early_stopper = EarlyStopping(patience=15, min_delta=0.001)\n",
    "\n",
    "    example_ct = 0\n",
    "    batch_ct = 0\n",
    "    for epoch in tqdm(range(config.epochs)):\n",
    "        model.train()\n",
    "        running_correct = 0\n",
    "        running_total = 0\n",
    "\n",
    "        for _, (images, labels) in enumerate(train_loader):\n",
    "            loss, batch_correct, batch_total = train_batch(images, labels, model, optimizer, criterion)\n",
    "            example_ct += len(images)\n",
    "            batch_ct += 1\n",
    "\n",
    "            running_correct += batch_correct\n",
    "            running_total += batch_total\n",
    "\n",
    "            if ((batch_ct + 1) % 25) == 0:\n",
    "                train_log(loss, example_ct, epoch)\n",
    "                print(f\"batch number: {batch_ct + 1}\")\n",
    "\n",
    "        train_acc = running_correct / running_total\n",
    "\n",
    "        # ⏱️ Validate at the end of the epoch\n",
    "        val_loss, val_acc = validate(model, val_loader, criterion)\n",
    "        wandb.log({\n",
    "            \"epoch\": epoch,\n",
    "            \"val_loss\": val_loss,\n",
    "            \"val_accuracy\": val_acc,\n",
    "            \"train_accuracy\": train_acc\n",
    "        })\n",
    "        print(f\"Epoch {epoch + 1}: val_loss = {val_loss:.4f}, val_acc = {val_acc:.4f}, train_acc = {train_acc:.4f}\")\n",
    "\n",
    "        # Check early stopping\n",
    "        early_stopper(val_loss)\n",
    "        if early_stopper.early_stop:\n",
    "            print(f\"Early stopping triggered at epoch {epoch + 1}\")\n",
    "            break\n",
    "def train_batch(images, labels, model, optimizer, criterion):\n",
    "    images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "    outputs = model(images)\n",
    "    loss = criterion(outputs, labels)\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    _, predicted = torch.max(outputs, 1)\n",
    "    correct = (predicted == labels).sum().item()\n",
    "    total = labels.size(0)\n",
    "\n",
    "    return loss, correct, total"
   ],
   "metadata": {
    "id": "2gDrRJB56ihi"
   },
   "id": "2gDrRJB56ihi",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## normal training"
   ],
   "metadata": {
    "id": "Ts0xewao6rsq"
   },
   "id": "Ts0xewao6rsq"
  },
  {
   "cell_type": "code",
   "source": [
    "import torch\n",
    "from tqdm import tqdm\n",
    "import wandb\n",
    "from sklearn.metrics import confusion_matrix, f1_score\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def train(model, train_loader, val_loader, criterion, optimizer, config, class_names= [\"Angry\", \"Disgust\", \"Fear\", \"Happy\", \"Sad\", \"Surprise\", \"Neutral\"]):\n",
    "    # wandb.init(\n",
    "    #     project=\"\",\n",
    "    #     config={\n",
    "    #         \"epochs\": config.epochs,\n",
    "    #         \"batch_size\": train_loader.batch_size,\n",
    "    #         \"optimizer\": optimizer.__class__.__name__,\n",
    "    #         \"lr\": optimizer.param_groups[0][\"lr\"],\n",
    "    #         \"criterion\": criterion.__class__.__name__,\n",
    "    #     }\n",
    "    # )\n",
    "    # wandb.watch(model, log=\"all\", log_freq=100)\n",
    "    model.to(config.device)\n",
    "\n",
    "    train_loss_plot, val_loss_plot = [], []\n",
    "    train_acc_plot, val_acc_plot = [], []\n",
    "\n",
    "    for epoch in range(config.epochs):\n",
    "        # Training\n",
    "        model.train()\n",
    "        total_train_loss, train_correct, train_total = 0.0, 0, 0\n",
    "\n",
    "        for images, labels in tqdm(train_loader, desc=f\"Epoch {epoch + 1} [Train]\"):\n",
    "            images, labels = images.to(config.device), labels.to(config.device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            total_train_loss += loss.item() * images.size(0)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            train_total += labels.size(0)\n",
    "            train_correct += (predicted == labels).sum().item()\n",
    "\n",
    "        train_loss = total_train_loss / train_total\n",
    "        train_acc = train_correct / train_total\n",
    "\n",
    "        # Validation\n",
    "        val_loss, val_acc, all_targets, all_preds = validate(model, val_loader, criterion, config.device)\n",
    "\n",
    "        # F1 and Confusion Matrix\n",
    "        cm = confusion_matrix(all_targets, all_preds)\n",
    "        f1_per_class = f1_score(all_targets, all_preds, average=None)\n",
    "\n",
    "        log_data = {\n",
    "            \"epoch\": epoch + 1,\n",
    "            \"train_loss\": train_loss,\n",
    "            \"train_acc\": train_acc,\n",
    "            \"val_loss\": val_loss,\n",
    "            \"val_acc\": val_acc,\n",
    "        }\n",
    "        for i, name in enumerate(class_names):\n",
    "            log_data[f\"f1_{name}\"] = f1_per_class[i]\n",
    "        wandb.log(log_data)\n",
    "\n",
    "        # Confusion matrix image\n",
    "        fig, ax = plt.subplots(figsize=(6,6))\n",
    "        im = ax.imshow(cm, cmap=\"Blues\")\n",
    "        fig.colorbar(im, ax=ax)\n",
    "        ax.set_xticks(np.arange(len(class_names)))\n",
    "        ax.set_yticks(np.arange(len(class_names)))\n",
    "        ax.set_xticklabels(class_names, rotation=45, ha=\"right\")\n",
    "        ax.set_yticklabels(class_names)\n",
    "        for i in range(len(class_names)):\n",
    "            for j in range(len(class_names)):\n",
    "                ax.text(j, i, cm[i, j], ha=\"center\", va=\"center\")\n",
    "        ax.set_title(f\"Confusion Matrix - Epoch {epoch+1}\")\n",
    "        ax.set_xlabel(\"Predicted\")\n",
    "        ax.set_ylabel(\"Actual\")\n",
    "        wandb.log({\"confusion_matrix\": wandb.Image(fig)})\n",
    "        plt.close(fig)\n",
    "\n",
    "        # Store for final plots\n",
    "        train_loss_plot.append(train_loss)\n",
    "        val_loss_plot.append(val_loss)\n",
    "        train_acc_plot.append(train_acc)\n",
    "        val_acc_plot.append(val_acc)\n",
    "\n",
    "        print(f\"Epoch {epoch+1}/{config.epochs}: \"\n",
    "              f\"Train Loss={train_loss:.4f}, Train Acc={train_acc:.4f} | \"\n",
    "              f\"Val Loss={val_loss:.4f}, Val Acc={val_acc:.4f}\")\n",
    "\n",
    "    # Final loss/accuracy curves\n",
    "    epochs_range = list(range(1, config.epochs + 1))\n",
    "\n",
    "    fig1, ax1 = plt.subplots()\n",
    "    ax1.plot(epochs_range, train_loss_plot, label=\"Train Loss\")\n",
    "    ax1.plot(epochs_range, val_loss_plot, label=\"Val Loss\")\n",
    "    ax1.set_title(\"Loss vs Epoch\")\n",
    "    ax1.set_xlabel(\"Epoch\")\n",
    "    ax1.set_ylabel(\"Loss\")\n",
    "    ax1.legend()\n",
    "    wandb.log({\"loss_curve\": wandb.Image(fig1)})\n",
    "    plt.close(fig1)\n",
    "\n",
    "    fig2, ax2 = plt.subplots()\n",
    "    ax2.plot(epochs_range, train_acc_plot, label=\"Train Accuracy\")\n",
    "    ax2.plot(epochs_range, val_acc_plot, label=\"Val Accuracy\")\n",
    "    ax2.set_title(\"Accuracy vs Epoch\")\n",
    "    ax2.set_xlabel(\"Epoch\")\n",
    "    ax2.set_ylabel(\"Accuracy\")\n",
    "    ax2.legend()\n",
    "    wandb.log({\"accuracy_curve\": wandb.Image(fig2)})\n",
    "    plt.close(fig2)\n",
    "\n",
    "    return model\n",
    "\n",
    "def validate(model, val_loader, criterion, device):\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    correct, total = 0, 0\n",
    "    all_preds, all_targets = [], []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in val_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            val_loss += loss.item() * images.size(0)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "            all_preds.extend(predicted.cpu().numpy())\n",
    "            all_targets.extend(labels.cpu().numpy())\n",
    "\n",
    "    avg_val_loss = val_loss / total\n",
    "    val_acc = correct / total\n",
    "    return avg_val_loss, val_acc, all_targets, all_preds\n",
    "\n",
    "import torch\n",
    "from sklearn.metrics import confusion_matrix, f1_score, classification_report\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import wandb\n",
    "\n",
    "def test(model, test_loader, device, class_names=None):\n",
    "    model.eval()\n",
    "    correct, total = 0, 0\n",
    "    all_preds, all_targets = [], []\n",
    "    misclassified_images = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in test_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "            all_preds.extend(predicted.cpu().numpy())\n",
    "            all_targets.extend(labels.cpu().numpy())\n",
    "\n",
    "            # Save misclassified images\n",
    "            mis_mask = (predicted != labels)\n",
    "            mis_imgs = images[mis_mask]\n",
    "            mis_lbls = labels[mis_mask]\n",
    "            mis_preds = predicted[mis_mask]\n",
    "            for img, true_lbl, pred_lbl in zip(mis_imgs, mis_lbls, mis_preds):\n",
    "                misclassified_images.append((img.cpu(), true_lbl.item(), pred_lbl.item()))\n",
    "\n",
    "    acc = correct / total\n",
    "    f1_macro = f1_score(all_targets, all_preds, average=\"macro\")\n",
    "    f1_per_class = f1_score(all_targets, all_preds, average=None)\n",
    "\n",
    "    print(f\"\\nTest Accuracy: {acc:.2%}\")\n",
    "    print(f\"F1 Macro: {f1_macro:.4f}\")\n",
    "    print(\"\\nClassification Report:\\n\", classification_report(all_targets, all_preds, target_names=class_names))\n",
    "\n",
    "    # Log numeric metrics\n",
    "    log_data = {\n",
    "        \"test_accuracy\": acc,\n",
    "        \"test_f1_macro\": f1_macro,\n",
    "    }\n",
    "    if class_names:\n",
    "        for i, name in enumerate(class_names):\n",
    "            log_data[f\"f1_{name}\"] = f1_per_class[i]\n",
    "    wandb.log(log_data)\n",
    "\n",
    "    # Confusion matrix\n",
    "    cm = confusion_matrix(all_targets, all_preds)\n",
    "    fig, ax = plt.subplots(figsize=(8, 6))\n",
    "    sns.heatmap(\n",
    "        cm,\n",
    "        annot=True,\n",
    "        fmt=\"d\",\n",
    "        xticklabels=class_names if class_names else \"auto\",\n",
    "        yticklabels=class_names if class_names else \"auto\",\n",
    "        cmap=\"Blues\"\n",
    "    )\n",
    "    ax.set_xlabel(\"Predicted\")\n",
    "    ax.set_ylabel(\"Actual\")\n",
    "    ax.set_title(\"Confusion Matrix (Test)\")\n",
    "    # wandb.log({\n",
    "    #     \"confusion_matrix_final\": wandb.Image(fig),\n",
    "    #     \"confusion_matrix_raw\": wandb.Table(data=cm.tolist(), columns=class_names, rows=class_names),\n",
    "    # })\n",
    "    plt.close(fig)\n",
    "\n",
    "    wandb.log({\n",
    "    \"confusion_matrix_final\": wandb.Image(fig),\n",
    "    \"confusion_matrix_raw\": wandb.plot.confusion_matrix(\n",
    "        probs=None,\n",
    "        y_true=all_targets,\n",
    "        preds=all_preds,\n",
    "        class_names=class_names if class_names else None\n",
    "    )\n",
    "})\n",
    "    # Log a few misclassified images\n",
    "    if class_names:\n",
    "        wrong_table = wandb.Table(columns=[\"Image\", \"True Label\", \"Predicted Label\"])\n",
    "        for img, true_lbl, pred_lbl in misclassified_images[:25]:\n",
    "            img_np = img.squeeze().numpy()  # assumes grayscale\n",
    "            wrong_table.add_data(\n",
    "                wandb.Image(img_np, caption=f\"Pred: {class_names[pred_lbl]}, GT: {class_names[true_lbl]}\"),\n",
    "                class_names[true_lbl],\n",
    "                class_names[pred_lbl]\n",
    "            )\n",
    "        wandb.log({\"misclassified_samples\": wrong_table})\n",
    "\n",
    "    # Export ONNX\n",
    "    dummy_input = torch.randn(1, *images.shape[1:]).to(device)\n",
    "    torch.onnx.export(model, dummy_input, \"model.onnx\")\n",
    "    wandb.save(\"model.onnx\")\n",
    "\n",
    "    # Optionally log model architecture as a string\n",
    "    model_arch_str = str(model)\n",
    "    wandb.log({\"model_architecture\": wandb.Html(f\"<pre>{model_arch_str}</pre>\")})\n",
    "\n",
    "\n",
    "\n",
    "def Final_test(model, test_loader, device, class_names=None):\n",
    "    model.eval()\n",
    "    correct, total = 0, 0\n",
    "    all_preds, all_targets = [], []\n",
    "    misclassified_images = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in test_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "            all_preds.extend(predicted.cpu().numpy())\n",
    "            all_targets.extend(labels.cpu().numpy())\n",
    "\n",
    "            # Save misclassified images\n",
    "            mis_mask = (predicted != labels)\n",
    "            mis_imgs = images[mis_mask]\n",
    "            mis_lbls = labels[mis_mask]\n",
    "            mis_preds = predicted[mis_mask]\n",
    "            for img, true_lbl, pred_lbl in zip(mis_imgs, mis_lbls, mis_preds):\n",
    "                misclassified_images.append((img.cpu(), true_lbl.item(), pred_lbl.item()))\n",
    "\n",
    "    acc = correct / total\n",
    "    f1_macro = f1_score(all_targets, all_preds, average=\"macro\")\n",
    "    f1_per_class = f1_score(all_targets, all_preds, average=None)\n",
    "\n",
    "    print(f\"\\nFinal_Test Accuracy: {acc:.2%}\")\n",
    "    print(f\"Final_F1 Macro: {f1_macro:.4f}\")\n",
    "    print(\"\\nFinal_Classification Report:\\n\", classification_report(all_targets, all_preds, target_names=class_names))\n",
    "\n",
    "    # Log numeric metrics\n",
    "    log_data = {\n",
    "        \"Final_test_accuracy\": acc,\n",
    "        \"Final_test_f1_macro\": f1_macro,\n",
    "    }\n",
    "    if class_names:\n",
    "        for i, name in enumerate(class_names):\n",
    "            log_data[f\"f1_{name}\"] = f1_per_class[i]\n",
    "    wandb.log(log_data)\n",
    "\n",
    "    # Confusion matrix\n",
    "    cm = confusion_matrix(all_targets, all_preds)\n",
    "    fig, ax = plt.subplots(figsize=(8, 6))\n",
    "    sns.heatmap(\n",
    "        cm,\n",
    "        annot=True,\n",
    "        fmt=\"d\",\n",
    "        xticklabels=class_names if class_names else \"auto\",\n",
    "        yticklabels=class_names if class_names else \"auto\",\n",
    "        cmap=\"Blues\"\n",
    "    )\n",
    "    ax.set_xlabel(\"Final_Predicted\")\n",
    "    ax.set_ylabel(\"Final_Actual\")\n",
    "    ax.set_title(\"Final_Confusion Matrix (Test)\")\n",
    "    # wandb.log({\n",
    "    #     \"confusion_matrix_final\": wandb.Image(fig),\n",
    "    #     \"confusion_matrix_raw\": wandb.Table(data=cm.tolist(), columns=class_names, rows=class_names),\n",
    "    # })\n",
    "    plt.close(fig)\n",
    "\n",
    "    wandb.log({\n",
    "    \"Final_confusion_matrix_final\": wandb.Image(fig),\n",
    "    \"Final_confusion_matrix_raw\": wandb.plot.confusion_matrix(\n",
    "        probs=None,\n",
    "        y_true=all_targets,\n",
    "        preds=all_preds,\n",
    "        class_names=class_names if class_names else None\n",
    "    )\n",
    "})\n",
    "    # Log a few misclassified images\n",
    "    if class_names:\n",
    "        wrong_table = wandb.Table(columns=[\"Image\", \"True Label\", \"Predicted Label\"])\n",
    "        for img, true_lbl, pred_lbl in misclassified_images[:25]:\n",
    "            img_np = img.squeeze().numpy()  # assumes grayscale\n",
    "            wrong_table.add_data(\n",
    "                wandb.Image(img_np, caption=f\"Pred: {class_names[pred_lbl]}, GT: {class_names[true_lbl]}\"),\n",
    "                class_names[true_lbl],\n",
    "                class_names[pred_lbl]\n",
    "            )\n",
    "        wandb.log({\"Final_misclassified_samples\": wrong_table})\n",
    "\n",
    "    # Export ONNX\n",
    "    dummy_input = torch.randn(1, *images.shape[1:]).to(device)\n",
    "    # torch.onnx.export(model, dummy_input, \"model.onnx\")\n",
    "    # wandb.save(\"model.onnx\")\n",
    "\n",
    "    # Optionally log model architecture as a string\n",
    "    model_arch_str = str(model)\n",
    "    wandb.log({\"Final_model_architecture\": wandb.Html(f\"<pre>{model_arch_str}</pre>\")})"
   ],
   "metadata": {
    "id": "F3VQ1HxlUk6V"
   },
   "id": "F3VQ1HxlUk6V",
   "execution_count": 22,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## pipeline"
   ],
   "metadata": {
    "id": "UU0HM605Auy7"
   },
   "id": "UU0HM605Auy7"
  },
  {
   "cell_type": "code",
   "source": [
    "def model_pipeline(hyperparameters):\n",
    "\n",
    "    # tell wandb to get started\n",
    "    with wandb.init(project=\"expression_dataset_final\",\n",
    "                    config=hyperparameters,\n",
    "                    name = \"resnet_og\"):\n",
    "      # access all HPs through wandb.config, so logging matches execution!\n",
    "      config = wandb.config\n",
    "\n",
    "      # make the model, data, and optimization problem\n",
    "      model, train_loader, test_loader, criterion, optimizer, final_test_loader = make(config)\n",
    "      print(model)\n",
    "\n",
    "      # and use them to train the model\n",
    "      # train(model, train_loader, criterion, optimizer, config)\n",
    "      wandb.watch(model, log=\"all\", log_freq=100)\n",
    "      # # and test its final performance\n",
    "      # test(model, test_loader)\n",
    "      train(model, train_loader, test_loader, criterion, optimizer, config)\n",
    "      test(model, test_loader, config.device)  # final test; you can use actual test set here if available\n",
    "      Final_test(model, final_test_loader,config.device)\n",
    "\n",
    "    wandb.finish()\n",
    "    return model"
   ],
   "metadata": {
    "id": "cEsYfYCkUbYw"
   },
   "id": "cEsYfYCkUbYw",
   "execution_count": 70,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "config = dict(\n",
    "    epochs=20,\n",
    "    classes=7,\n",
    "    #kernels=[32, 64, 128],\n",
    "    batch_size=256,\n",
    "    learning_rate=.3e-4,\n",
    "    dataset=\"Facial Expression Recognition\",\n",
    "    architecture=\"resnet_og\",\n",
    "    device = device,\n",
    "    weight_decay = 1e-4)"
   ],
   "metadata": {
    "id": "GoXMnqIWY9fa"
   },
   "id": "GoXMnqIWY9fa",
   "execution_count": 83,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "total = 0\n",
    "train_dataset = get_data(train=True)\n",
    "test_dataset = get_data(train=False)\n",
    "train_loader = make_loader(train_dataset, batch_size=config['batch_size'])\n",
    "test_loader = make_loader(test_dataset, batch_size=config['batch_size'])\n",
    "for batch in train_loader:\n",
    "    images, labels = batch\n",
    "    total += len(images)\n",
    "# Count class occurrences\n",
    "all_labels = []\n",
    "for _, labels in train_loader:\n",
    "    all_labels.extend(labels.tolist())\n",
    "\n",
    "label_counts = Counter(all_labels)\n",
    "\n",
    "# Print counts\n",
    "print(\"Label distribution in augmented training data:\")\n",
    "for label, count in sorted(label_counts.items()):\n",
    "    print(f\"Class {label}: {count} samples\")\n",
    "\n",
    "# Optional: plot for visual confirmation\n",
    "plt.bar(label_counts.keys(), label_counts.values(), tick_label=[str(i) for i in label_counts.keys()])\n",
    "plt.xlabel('Emotion Class')\n",
    "plt.ylabel('Number of Samples')\n",
    "plt.title('Class Distribution After Augmentation')\n",
    "plt.show()\n",
    "print(f\"Total images seen via train_loader: {total}\")"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 715
    },
    "id": "uTtkeP3VhRZO",
    "outputId": "1a6b68d6-d5b3-4ed5-d260-64f47639f2db"
   },
   "id": "uTtkeP3VhRZO",
   "execution_count": 42,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "‣ Loaded 'Training' => 28709 samples before augmentation/slicing.\n",
      "‣ Base dataset size: 28709\n",
      "‣ Augmenting 21796 extra samples to balance classes.\n",
      "‣ Resulting dataset size: 50505\n",
      "‣ Loaded 'PublicTest' => 3589 samples before augmentation/slicing.\n",
      "Label distribution in augmented training data:\n",
      "Class 0: 7215 samples\n",
      "Class 1: 7215 samples\n",
      "Class 2: 7215 samples\n",
      "Class 3: 7215 samples\n",
      "Class 4: 7215 samples\n",
      "Class 5: 7215 samples\n",
      "Class 6: 7215 samples\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ],
      "image/png": "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\n"
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Total images seen via train_loader: 50505\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# train!"
   ],
   "metadata": {
    "id": "MQvkFnUNxXls"
   },
   "id": "MQvkFnUNxXls"
  },
  {
   "cell_type": "code",
   "source": [
    "model = model_pipeline(config)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "MifXx_iuXfLi",
    "outputId": "7b755ec7-89bb-4462-9bf0-06c1a9b4d19f"
   },
   "id": "MifXx_iuXfLi",
   "execution_count": null,
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Tracking run with wandb version 0.19.11"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Run data is saved locally in <code>/content/wandb/run-20250605_183040-t2g05zn6</code>"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/arazm21-free-university-of-tbilisi-/expression_dataset_final/runs/t2g05zn6' target=\"_blank\">resnet_og</a></strong> to <a href='https://wandb.ai/arazm21-free-university-of-tbilisi-/expression_dataset_final' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       " View project at <a href='https://wandb.ai/arazm21-free-university-of-tbilisi-/expression_dataset_final' target=\"_blank\">https://wandb.ai/arazm21-free-university-of-tbilisi-/expression_dataset_final</a>"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       " View run at <a href='https://wandb.ai/arazm21-free-university-of-tbilisi-/expression_dataset_final/runs/t2g05zn6' target=\"_blank\">https://wandb.ai/arazm21-free-university-of-tbilisi-/expression_dataset_final/runs/t2g05zn6</a>"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "‣ Loaded 'Training' => 28709 samples before augmentation/slicing.\n",
      "‣ Base dataset size: 28709\n",
      "‣ Augmenting 21796 extra samples to balance classes.\n",
      "‣ Resulting dataset size: 50505\n",
      "‣ Loaded 'PublicTest' => 3589 samples before augmentation/slicing.\n",
      "‣ Loaded 'PublicTest' => 3589 samples before augmentation/slicing.\n",
      "ResNet(\n",
      "  (conv1): Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU()\n",
      "  (maxpool): Identity()\n",
      "  (layer1): Sequential(\n",
      "    (0): block(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU()\n",
      "      (identity_downsample): Sequential(\n",
      "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): block(\n",
      "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU()\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): block(\n",
      "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU()\n",
      "      (identity_downsample): Sequential(\n",
      "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): block(\n",
      "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU()\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): block(\n",
      "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU()\n",
      "      (identity_downsample): Sequential(\n",
      "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): block(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU()\n",
      "    )\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (0): block(\n",
      "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU()\n",
      "      (identity_downsample): Sequential(\n",
      "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): block(\n",
      "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU()\n",
      "    )\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (fc): Linear(in_features=2048, out_features=7, bias=True)\n",
      ")\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Epoch 1 [Train]: 100%|██████████| 198/198 [04:01<00:00,  1.22s/it]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/20: Train Loss=1.7717, Train Acc=0.2816 | Val Loss=1.7700, Val Acc=0.2965\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Epoch 2 [Train]:  41%|████▏     | 82/198 [01:40<02:21,  1.22s/it]"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "print(device)"
   ],
   "metadata": {
    "id": "PhusPwNHkvAx",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "b62f87b2-f01c-4699-f6d4-2348a2515f19"
   },
   "id": "PhusPwNHkvAx",
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "cuda:0\n"
     ]
    }
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  },
  "colab": {
   "provenance": [],
   "gpuType": "T4",
   "include_colab_link": true
  },
  "accelerator": "GPU"
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
